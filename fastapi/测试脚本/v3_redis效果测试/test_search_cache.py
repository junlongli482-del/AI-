"""
æœç´¢ç»“æœç¼“å­˜æµ‹è¯•è„šæœ¬
æµ‹è¯•æœç´¢åŠŸèƒ½çš„ç¼“å­˜ä¼˜åŒ–
"""

import requests
import json
from datetime import datetime
import urllib.parse

# é…ç½®
BASE_URL = "http://localhost:8100/api/v2/tech_square"

def test_search_cache():
    """æµ‹è¯•æœç´¢ç¼“å­˜åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•æœç´¢ç»“æœç¼“å­˜")
    print("=" * 50)

    # ä½¿ç”¨ç¡®å®å­˜åœ¨çš„å…³é”®è¯è¿›è¡Œæµ‹è¯•
    test_cases = [
        {"keyword": "00", "page": 1, "size": 10, "file_type": None},
        {"keyword": "10", "page": 1, "size": 5, "file_type": None},
        {"keyword": "AI", "page": 1, "size": 10, "file_type": "md"},
        {"keyword": "æ¨¡å—", "page": 1, "size": 20, "file_type": None},
        {"keyword": "è®¡åˆ’", "page": 1, "size": 15, "file_type": None},
    ]

    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“Š æµ‹è¯•ç”¨ä¾‹ {i}: {case}")

        # æ„å»ºURL
        params = {
            "keyword": case["keyword"],
            "page": case["page"],
            "size": case["size"]
        }
        if case["file_type"]:
            params["file_type"] = case["file_type"]

        url = f"{BASE_URL}/search?" + "&".join([f"{k}={urllib.parse.quote(str(v))}" for k, v in params.items()])

        # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        print("ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆé¢„æœŸç¼“å­˜æœªå‘½ä¸­ï¼‰:")
        response1 = requests.get(url)
        print(f"çŠ¶æ€ç : {response1.status_code}")

        if response1.status_code == 200:
            data1 = response1.json()
            print(f"æœç´¢ç»“æœ: å½“å‰é¡µ{len(data1.get('documents', []))}æ¡, æ€»è®¡{data1.get('total', 0)}æ¡")
            cache_info1 = data1.get('cache_info', {})
            print(f"ç¼“å­˜çŠ¶æ€: {cache_info1}")

            # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
            print("\nç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆé¢„æœŸç¼“å­˜å‘½ä¸­ï¼‰:")
            response2 = requests.get(url)
            print(f"çŠ¶æ€ç : {response2.status_code}")

            if response2.status_code == 200:
                data2 = response2.json()
                print(f"æœç´¢ç»“æœ: å½“å‰é¡µ{len(data2.get('documents', []))}æ¡, æ€»è®¡{data2.get('total', 0)}æ¡")
                cache_info2 = data2.get('cache_info', {})
                print(f"ç¼“å­˜çŠ¶æ€: {cache_info2}")

                # éªŒè¯ç¼“å­˜å‘½ä¸­
                if cache_info2.get('cached'):
                    print("âœ… ç¼“å­˜å‘½ä¸­æµ‹è¯•é€šè¿‡")
                else:
                    print("âŒ ç¼“å­˜å‘½ä¸­æµ‹è¯•å¤±è´¥")

                # éªŒè¯ç»“æœä¸€è‡´æ€§
                if data1.get('total') == data2.get('total'):
                    print("âœ… ç»“æœä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
                else:
                    print("âŒ ç»“æœä¸€è‡´æ€§æµ‹è¯•å¤±è´¥")
            else:
                print(f"âŒ ç¬¬äºŒæ¬¡è¯·æ±‚å¤±è´¥: {response2.text}")
        else:
            print(f"âŒ ç¬¬ä¸€æ¬¡è¯·æ±‚å¤±è´¥: {response1.text}")

def test_search_key_isolation():
    """æµ‹è¯•æœç´¢ç¼“å­˜Keyéš”ç¦»"""
    print("\nğŸ”‘ æµ‹è¯•æœç´¢ç¼“å­˜Keyéš”ç¦»")
    print("=" * 50)

    # ä½¿ç”¨å­˜åœ¨çš„å…³é”®è¯æµ‹è¯•ç›¸åŒå…³é”®è¯ä¸åŒå‚æ•°çš„ç¼“å­˜éš”ç¦»
    base_params = {"keyword": "AI", "page": 1, "size": 10}

    test_variations = [
        {**base_params},  # åŸºç¡€å‚æ•°
        {**base_params, "size": 5},  # ä¸åŒsize
        {**base_params, "page": 2},  # ä¸åŒpage
        {**base_params, "file_type": "md"},  # ä¸åŒfile_type
    ]

    for i, params in enumerate(test_variations, 1):
        print(f"\nğŸ” å˜ä½“ {i}: {params}")

        url = f"{BASE_URL}/search?" + "&".join([f"{k}={urllib.parse.quote(str(v))}" for k, v in params.items()])

        # ä¸¤æ¬¡è¯·æ±‚éªŒè¯ç¼“å­˜
        response1 = requests.get(url)
        response2 = requests.get(url)

        if response1.status_code == 200 and response2.status_code == 200:
            cache_info1 = response1.json().get('cache_info', {})
            cache_info2 = response2.json().get('cache_info', {})

            print(f"ç¬¬ä¸€æ¬¡: ç¼“å­˜={cache_info1.get('cached', False)}")
            print(f"ç¬¬äºŒæ¬¡: ç¼“å­˜={cache_info2.get('cached', False)}")

            if not cache_info1.get('cached') and cache_info2.get('cached'):
                print("âœ… ç¼“å­˜Keyéš”ç¦»æ­£å¸¸")
            else:
                print("âŒ ç¼“å­˜Keyéš”ç¦»å¼‚å¸¸")

def test_chinese_keyword_search():
    """æµ‹è¯•ä¸­æ–‡å…³é”®è¯æœç´¢ç¼“å­˜"""
    print("\nğŸ‡¨ğŸ‡³ æµ‹è¯•ä¸­æ–‡å…³é”®è¯æœç´¢ç¼“å­˜")
    print("=" * 50)

    # ä½¿ç”¨ç¡®å®å­˜åœ¨çš„ä¸­æ–‡å…³é”®è¯
    chinese_keywords = ["æ¨¡å—", "è®¡åˆ’"]

    for keyword in chinese_keywords:
        print(f"\nğŸ” æµ‹è¯•ä¸­æ–‡å…³é”®è¯: '{keyword}'")

        url = f"{BASE_URL}/search?keyword={urllib.parse.quote(keyword)}&page=1&size=10"

        # ä¸¤æ¬¡è¯·æ±‚éªŒè¯ç¼“å­˜
        response1 = requests.get(url)
        response2 = requests.get(url)

        if response1.status_code == 200 and response2.status_code == 200:
            data1 = response1.json()
            data2 = response2.json()

            cache_info1 = data1.get('cache_info', {})
            cache_info2 = data2.get('cache_info', {})

            print(f"ç¬¬ä¸€æ¬¡: ç¼“å­˜={cache_info1.get('cached', False)}, ç»“æœ={len(data1.get('documents', []))}æ¡")
            print(f"ç¬¬äºŒæ¬¡: ç¼“å­˜={cache_info2.get('cached', False)}, ç»“æœ={len(data2.get('documents', []))}æ¡")

            if cache_info2.get('cached'):
                print("âœ… ä¸­æ–‡å…³é”®è¯ç¼“å­˜æ­£å¸¸")
            else:
                print("âŒ ä¸­æ–‡å…³é”®è¯ç¼“å­˜å¤±è´¥")

def test_numeric_keyword_search():
    """æµ‹è¯•æ•°å­—å…³é”®è¯æœç´¢ç¼“å­˜"""
    print("\nğŸ”¢ æµ‹è¯•æ•°å­—å…³é”®è¯æœç´¢ç¼“å­˜")
    print("=" * 50)

    # ä½¿ç”¨ç¡®å®å­˜åœ¨çš„æ•°å­—å…³é”®è¯
    numeric_keywords = ["00", "10"]

    for keyword in numeric_keywords:
        print(f"\nğŸ” æµ‹è¯•æ•°å­—å…³é”®è¯: '{keyword}'")

        url = f"{BASE_URL}/search?keyword={keyword}&page=1&size=10"

        # ä¸¤æ¬¡è¯·æ±‚éªŒè¯ç¼“å­˜
        response1 = requests.get(url)
        response2 = requests.get(url)

        if response1.status_code == 200 and response2.status_code == 200:
            data1 = response1.json()
            data2 = response2.json()

            cache_info1 = data1.get('cache_info', {})
            cache_info2 = data2.get('cache_info', {})

            print(f"ç¬¬ä¸€æ¬¡: ç¼“å­˜={cache_info1.get('cached', False)}, ç»“æœ={len(data1.get('documents', []))}æ¡")
            print(f"ç¬¬äºŒæ¬¡: ç¼“å­˜={cache_info2.get('cached', False)}, ç»“æœ={len(data2.get('documents', []))}æ¡")

            if cache_info2.get('cached'):
                print("âœ… æ•°å­—å…³é”®è¯ç¼“å­˜æ­£å¸¸")
            else:
                print("âŒ æ•°å­—å…³é”®è¯ç¼“å­˜å¤±è´¥")

def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("\nâš¡ æµ‹è¯•æœç´¢ç¼“å­˜æ€§èƒ½å¯¹æ¯”")
    print("=" * 50)

    import time

    # ä½¿ç”¨ä¸€ä¸ªå­˜åœ¨çš„å…³é”®è¯è¿›è¡Œæ€§èƒ½æµ‹è¯•
    test_keyword = "AI"
    url = f"{BASE_URL}/search?keyword={test_keyword}&page=1&size=10"

    print(f"ğŸ” æ€§èƒ½æµ‹è¯•å…³é”®è¯: '{test_keyword}'")

    # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    start_time = time.time()
    response1 = requests.get(url)
    first_request_time = (time.time() - start_time) * 1000

    if response1.status_code == 200:
        data1 = response1.json()
        print(f"ç¬¬ä¸€æ¬¡è¯·æ±‚è€—æ—¶: {first_request_time:.2f}ms")
        print(f"æœç´¢ç»“æœ: {len(data1.get('documents', []))}æ¡")

        # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
        start_time = time.time()
        response2 = requests.get(url)
        second_request_time = (time.time() - start_time) * 1000

        if response2.status_code == 200:
            data2 = response2.json()
            print(f"ç¬¬äºŒæ¬¡è¯·æ±‚è€—æ—¶: {second_request_time:.2f}ms")
            print(f"æœç´¢ç»“æœ: {len(data2.get('documents', []))}æ¡")

            if first_request_time > 0 and second_request_time > 0:
                improvement = ((first_request_time - second_request_time) / first_request_time) * 100
                print(f"æ€§èƒ½æå‡: {improvement:.1f}%")

                if improvement > 0:
                    print("âœ… æ€§èƒ½æå‡æµ‹è¯•é€šè¿‡")
                else:
                    print("âŒ æ€§èƒ½æå‡æµ‹è¯•å¤±è´¥")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æœç´¢ç»“æœç¼“å­˜åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•åœ°å€: {BASE_URL}")
    print(f"æµ‹è¯•å…³é”®è¯: 00, 10, AI, æ¨¡å—, è®¡åˆ’")

    try:
        # æµ‹è¯•åŸºç¡€æœç´¢ç¼“å­˜
        test_search_cache()

        # æµ‹è¯•ç¼“å­˜Keyéš”ç¦»
        test_search_key_isolation()

        # æµ‹è¯•ä¸­æ–‡å…³é”®è¯
        test_chinese_keyword_search()

        # æµ‹è¯•æ•°å­—å…³é”®è¯
        test_numeric_keyword_search()

        # æµ‹è¯•æ€§èƒ½å¯¹æ¯”
        test_performance_comparison()

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()